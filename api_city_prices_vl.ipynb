{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API City prices for living cost from numbeo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import sql_functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_dotenv to be able to pull the API key from the .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info from API numbeo.com\n",
    "\n",
    "yearLastUpdate': 2023\n",
    "\n",
    "Our daily_cost_bucket:\n",
    "\n",
    "'item_id': 1, 'item_name': 'Meal, Inexpensive Restaurant, Restaurants'\n",
    "\n",
    "'item_id': 3, 'item_name': 'McMeal at McDonalds (or Equivalent Combo Meal), Restaurants'\n",
    "\n",
    "'item_id': 4, 'item_name': 'Domestic Beer (0.5 liter draught), Restaurants'\n",
    "\n",
    "'item_id': 7, 'item_name': 'Water (0.33 liter bottle), Restaurants'\n",
    "\n",
    "'item_id': 114, 'item_name': 'Cappuccino (regular), Restaurants'\n",
    "\n",
    "'item_id': 13, 'item_name': 'Water (1.5 liter bottle), Markets'\n",
    "\n",
    "'item_id': 18, 'item_name': 'One-way Ticket (Local Transport), Transportation'\n",
    "\n",
    "'item_id': 108, 'item_name': 'Taxi 1km (Normal Tariff), Transportation'\n",
    "\n",
    "'item_id': 26, 'item_name': 'One bed apartment in city centre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load city list from data/cities_numbeo excel file\n",
    "city_list = pd.read_excel('data/Cities_numbeo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the list in three columns on comma ' , ' \n",
    "city_list[['city', 'country', 'country_2']] = city_list['City'].str.split(', ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'country' column in the city_list df with values from the 'country_2' column, but only for rows where 'country_2' is not null\n",
    "city_list.loc[city_list['country_2'].notnull(), 'country'] = city_list['country_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique vvalues in country column\n",
    "city_list['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns \"city\" and \"country_2\"\n",
    "city_list.drop(['City', 'country_2'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the 'city' column from the city_list df, convert it to list and store it in the variable 'city'\n",
    "city = list(city_list['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the 'country' column from the city_list df, convert it to list and store it in the variable 'country'\n",
    "country = list(city_list['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with city and country for the API query\n",
    "city_count_dict = dict(zip(city, country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #API download from www.numbeo.com \n",
    "url = 'https://www.numbeo.com/api/city_prices'\n",
    "api_key = os.getenv('numbeo_api_key') # extract the value for the api key\n",
    "#country_list ' don`t need, we take the values for countries from country_list in cell above \n",
    "desired_item_ids = [1, 3, 4, 7, 114, 13, 18, 108, 26]\n",
    "currency = \"EUR\"\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for city in city:\n",
    "    # Send the HTTP GET request for each country with currency parameter\n",
    "    response = requests.get(url, params={\"api_key\": api_key, \"query\": city, \"currency\": currency})\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Access the \"prices\" list from the response\n",
    "        prices = data.get(\"prices\", [])\n",
    "        \n",
    "        # Access the country's land information\n",
    "        city = city\n",
    "        \n",
    "        # Initialize a list to store the desired items for the country\n",
    "        desired_items = []\n",
    "        \n",
    "        # Iterate over the prices and check if the item_id matches the desired values\n",
    "        for price in prices:\n",
    "            item_id = price.get(\"item_id\")\n",
    "            if item_id in desired_item_ids:\n",
    "                desired_items.append(price)\n",
    "        \n",
    "        # Add the desired items, land information, and currency to the data list\n",
    "        for item in desired_items:\n",
    "            item[\"city\"] = city\n",
    "            item[\"currency\"] = currency\n",
    "        data_list.extend(desired_items)\n",
    "    else:\n",
    "        print(f\"Request for {city} failed with status code:\", response.status_code)\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df backup for emergency cases\n",
    "df_backup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column data_points, item_id, lowest_price and highest_price and store the data in a \"df_new\"\n",
    "df_new = df.drop([\"data_points\", 'lowest_price', 'highest_price', 'currency'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the column country by going though the city_count_dict \n",
    "df_new['country'] = df_new['city'].map(city_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the entire df without truncation for all cells/dfs in this document\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price_per_day and calc_price for rows where the item_id = 26 and store them in the particular column\n",
    "df_new.loc[df_new['item_id'] == 26, 'price_per_day'] = df_new.loc[df_new['item_id'] == 26, 'average_price'] / 30\n",
    "df_new.loc[df_new['item_id'] == 26, 'calc_price'] = df_new.loc[df_new['item_id'] == 26, 'price_per_day'] * 3.89\n",
    "\n",
    "# for other rows where item_id is not 26, fill with NaN or any other default value\n",
    "df_new.loc[df_new['item_id'] != 26, ['price_per_day', 'calc_price']] = None\n",
    "\n",
    "df_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the 'average_price' column in df_new with values from the 'calc_price' column, but only for rows where 'calc_price' is not null\n",
    "df_new.loc[df_new['calc_price'].notnull(), 'average_price'] = df_new['calc_price']\n",
    "\n",
    "df_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df named df_clean by dropping the columns \"price_per_day\" and \"calc_price\" (along the axis=1 (columns))\n",
    "df_clean = df_new.drop([\"price_per_day\", 'calc_price'], axis=1)\n",
    "\n",
    "df_clean.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the tax_max(new taxi price for 3km) for items with 'item_id' equal to 108 (current 1 km taxi price)\n",
    "df_clean.loc[df_clean['item_id'] == 108, 'tax_max'] = df_clean.loc[df_clean['item_id'] == 108, 'average_price'] * 3\n",
    "df_clean.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the 'average_price' column in df_clean with values from the 'tax_max' column, but only for rows where 'tax_max' is not null\n",
    "df_clean.loc[df_clean['tax_max'].notnull(), 'average_price'] = df_clean['tax_max']\n",
    "df_clean.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the column \"tax_max\" (along the axis=1 (columns))\n",
    "df_clean = df_clean.drop(['tax_max'], axis=1)\n",
    "df_clean.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'item_name' column in df_clean for rows where 'item_id' is 108 - replace 'Taxi 1km (Normal Tariff), Transportation' with 'Taxi 3km (Normal Tariff), Transportation'\n",
    "df_clean.loc[(df_clean['item_id'] == 108) & (df_clean['item_name'] == 'Taxi 1km (Normal Tariff), Transportation'), 'item_name'] = 'Taxi 3km (Normal Tariff), Transportation'\n",
    "\n",
    "df_clean.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_dataframe\n",
    "\n",
    "#Get the df with the airbnb prices from sql data base\n",
    "schema = 'capstone_travel_index'\n",
    "airbnb_df = get_dataframe(f'SELECT * FROM {schema}.airbnb_prices_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the columns with the other room types\n",
    "airbnb_df_clean = airbnb_df.drop(['Hotel room','Private room','Shared room'], axis=1)\n",
    "airbnb_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update 'average_price' in df_clean with 'Entire home/apt' value from airbnb_df_clean,\n",
    "# for rows where 'item_id' is 26 and 'city' matches the current iteration city\n",
    "for city in list(airbnb_df_clean['city']):\n",
    "    df_clean.loc[(df_clean['item_id'] == 26) & (df_clean['city'] == city), 'average_price'] = airbnb_df_clean.query(f\"city == '{city}'\")['Entire home/apt'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from country_iso_dict import country_iso_dict\n",
    "\n",
    "# Add a new column \"iso3\" with ISO3 values pulled from the dict in country_iso_dict.py (mapping)\n",
    "df_clean['iso3'] = df_clean['country'].map(country_iso_dict)\n",
    "\n",
    "df_clean.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df df_isnull with unique countries from df_clean where the 'iso3' column is null - countries where mapping has failed\n",
    "df_isnull = df_clean[df_clean['iso3'].isnull()].country.unique()\n",
    "df_isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new/complete dict for countries where mapping has failed\n",
    "missing_countries_dict = {\n",
    "    'United Kingdom': 'GBR',\n",
    "    'Ivory Coast': 'CIV',\n",
    "    'United States': 'USA',\n",
    "    'Bosnia And Herzegovina': 'BIH',\n",
    "    'Venezuela': 'VEN',\n",
    "    'Moldova': 'MDA',\n",
    "    'Vietnam': 'VNM',\n",
    "    'Syria': 'SYR',\n",
    "    'Tanzania': 'TZA',\n",
    "    'Isle Of Man': 'IMN',\n",
    "    'Hong Kong (China)': 'HKG',\n",
    "    'Iran': 'IRN',\n",
    "    'Russia': 'RUS',\n",
    "    'Taiwan': 'TWN',\n",
    "    'Macao (China)': 'MAC',\n",
    "    'Trinidad And Tobago': 'TTO',\n",
    "    'Kosovo (Disputed Territory)': 'XKX',\n",
    "    'Palestine': 'PSE',\n",
    "    'Bolivia': 'BOL',\n",
    "    'South Korea': 'KOR'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the NaN values in the 'iso3' column with the corresponding ISO3 values from the new dictionary\n",
    "df_clean.loc[df_clean['iso3'].isnull(), 'iso3'] = df_clean.loc[df_clean['iso3'].isnull(), 'country'].map(missing_countries_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for unique countries where the 'iso3' column is null - should be empty now\n",
    "df_isnull = df_clean[df_clean['iso3'].isnull()].country.unique()\n",
    "df_isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a items backup\n",
    "df_items_backup = df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a need df with item_id and item_name columns only - plus only the values of the first 9 rows of those columns\n",
    "df_items = df_clean[['item_id', 'item_name']]\n",
    "df_items.drop(df_items.index[9:], axis=0, inplace=True)\n",
    "df_items.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another backup\n",
    "df_backup_before_drop = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop of the column item_name\n",
    "df_clean.drop(['item_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates which have the same values in all 3 columns ('item_id', 'city', 'country')\n",
    "df_clean_drop = df_clean.drop_duplicates(['item_id', 'city', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_drop.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for combination of the 3 columns having the same values - should be empty now\n",
    "df_clean_drop[df_clean_drop.duplicated(['item_id', 'city', 'country'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another backup\n",
    "df_clean_drop_backup = df_clean_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table df_pivoted from the df_clean_drop df, using 'city' and 'iso3' as index,\n",
    "# 'item_id' as columns, and 'average_price' as the values to populate the table\n",
    "df_pivoted = df_clean_drop.pivot(index=['city', 'iso3'], columns=['item_id'], values='average_price').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function to check how many % of each column are NULL values\n",
    "from transform_esg import per_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_null(df_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a last backup and renaming of the final df\n",
    "df_city_prices_final = df_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_prices_final.head(18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the DataFrame df to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define schema for DBeaver\n",
    "schema = 'capstone_travel_index'\n",
    "engine = sf.get_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset \"df_city_prices_final\" to DBeaver\n",
    "table_name = 'city_prices_final'\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_city_prices_final.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short check before upload\n",
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset \"df_items\" to DBeaver\n",
    "table_name = 'df_items'\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_items.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
